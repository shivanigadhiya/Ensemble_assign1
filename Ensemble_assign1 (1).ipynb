{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2caec4-857e-4ece-96a6-e0adfaabed79",
   "metadata": {},
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9f512-b07a-41bf-af92-ef9ed7881736",
   "metadata": {},
   "source": [
    "It combines the multiple model , train them and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06242a7d-e580-4ac9-94fa-3b55f7bebcf6",
   "metadata": {},
   "source": [
    "There are two types of Ensemble technique : Bagging and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ed4a8-a77d-4d66-82ad-94b15dd83135",
   "metadata": {},
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e7e37-803e-4ee0-a6f5-b1669d2a5105",
   "metadata": {},
   "source": [
    "The underlying concept behind ensemble learning is to combine the outputs of diverse models to create a more precise prediction. By considering multiple perspectives and utilizing the strengths of different models, ensemble learning improves the overall performance of the learning system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574b942-5615-4fd2-99d6-12b09330ffd7",
   "metadata": {},
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f3aef-7f91-4e66-8b6c-f8c47cbfedd4",
   "metadata": {},
   "source": [
    "Bagging only uses multiple models called Base learners "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde97ced-50ee-46cf-84b2-f999c935866d",
   "metadata": {},
   "source": [
    "In Bagging Technique , It gives parallely data to models from the dataset , each and every models makes predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf96a0ab-af72-4f5b-9065-cd41cf94dba4",
   "metadata": {},
   "source": [
    "Out of all predictions that prediction is chosen which has majority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a8df9-5afa-46de-832b-e7b176453821",
   "metadata": {},
   "source": [
    "It combines the output using Yoting technique and gives output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb94a5-ba3b-467c-9db7-c2a1807c37f5",
   "metadata": {},
   "source": [
    "In bagging , Random Forest algorithm is popular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaeca05-a214-4458-b068-2bfa647dac36",
   "metadata": {},
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41150b23-144e-49be-ac02-f91d9fd19283",
   "metadata": {},
   "source": [
    "Boosting is used for both regression and cllassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b17319-7962-4d24-8bf8-e3b50004165f",
   "metadata": {},
   "source": [
    "In decision tree it splits until the leaf nodes. It causes overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def88500-638f-42a3-9721-13eb6d534ee2",
   "metadata": {},
   "source": [
    "In boosting it also uses decision tree but it gives data sequentialy to the models from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38878a23-83b3-42f3-bc2f-8f6ca0760962",
   "metadata": {},
   "source": [
    "example : DT1 model makes some predictions and it has many wrong prediction , these wrong predictions are given to the next Decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42843c48-5e5d-4669-a79b-919915b337a0",
   "metadata": {},
   "source": [
    "In Bagging : Majority voting or mean of all ouputs  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de44928-4bfd-43f1-9b92-2a5dbdd8c9d2",
   "metadata": {},
   "source": [
    "In boosting : Assignments of weights to the weak learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac629432-7ac9-49f1-86c6-1e55eb095c3b",
   "metadata": {},
   "source": [
    "Boosting has three techniques : Adaboost , Gradient Boost , Xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efbd51-5e7d-441a-b5db-785963d36495",
   "metadata": {},
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1023d8c-b0bf-4635-85d8-6b8783850ec4",
   "metadata": {},
   "source": [
    "Ensemble methods have higher predictive accuracy, compared to the individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514ef57-5a6d-4800-aa31-7e14a37ac3fe",
   "metadata": {},
   "source": [
    "Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; different models can be combined to handle this type of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbefd32-78a6-440c-bc86-3e8923df1024",
   "metadata": {},
   "source": [
    "With ensemble methods bias/variance can be reduced and most of the time, the model is not under fitted/overfitted.With ensemble methods bias/variance can be reduced and most of the time, the model is not under fitted/overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349801b0-4357-493a-bbf6-a37aeea48d52",
   "metadata": {},
   "source": [
    "Ensemble of models is always less noisy and more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb72e1-ece2-483e-b880-554f3c8cb834",
   "metadata": {},
   "source": [
    "Ensemble techniques are not always better than individual models, although they often provide significant improvements in many scenarios. Here are some points to consider regarding when ensemble methods might be advantageous and when they might not be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acb820-bc27-41d4-a8e2-50890ce3b894",
   "metadata": {},
   "source": [
    "Increased Complexity: Ensembles, particularly those involving many diverse models, can be difficult to interpret and understand compared to simpler, individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136e45a-4954-4d42-b25b-4f4b0bf531cf",
   "metadata": {},
   "source": [
    "Diminishing Returns: Beyond a certain point, adding more models to an ensemble might yield minimal improvements or even degrade performance if the additional models are not sufficiently diverse or are of poor quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54472f41-28a4-406f-b2c9-31e1f7992138",
   "metadata": {},
   "source": [
    "Overfitting with Boosting:\n",
    "\n",
    "Boosting Risk: While boosting methods like Gradient Boosting can reduce bias, they can also be prone to overfitting if not properly regularized and tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdd573-b6df-410a-86fa-99dcbef9d457",
   "metadata": {},
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d748c1-58c6-4da1-a200-078d3379516d",
   "metadata": {},
   "source": [
    "1.Generate Bootstrap Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74692f5-70df-4f96-a099-c672fbf97477",
   "metadata": {},
   "source": [
    "2.Calculate the Statistic for Each Bootstrap Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fcd65-dfca-4500-bc4b-7cec8a082ad8",
   "metadata": {},
   "source": [
    "3.Create the Bootstrap Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083dbcf6-2112-427b-82af-a53a7434d954",
   "metadata": {},
   "source": [
    "4.Determine the Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082df8e-3b08-4370-9e6c-cb896647a0e9",
   "metadata": {},
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05bc20-5c65-4629-8ece-af1df5aaf020",
   "metadata": {},
   "source": [
    "1.Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e3461-2a0b-4a41-818f-837446bd6222",
   "metadata": {},
   "source": [
    "2.We can create Decision Tree Stamp and we select best stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7b786-20a7-4b80-aaa7-20db4ec3b0ca",
   "metadata": {},
   "source": [
    "3.Entropy or Gini Impurity and Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f785b-4ea4-46ba-92f1-fa9a826e2418",
   "metadata": {},
   "source": [
    "4.Sum of total errors and performance of stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239eceb-c59f-44d1-8c9c-2f5aa0d9b21b",
   "metadata": {},
   "source": [
    "5.Performance of stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a91677-e8c6-4369-82f1-41cf66547f60",
   "metadata": {},
   "source": [
    "6.Update th weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdea0d-1c69-43e7-813c-4ecbb61f5c2c",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e885b87e-fa83-483b-81a0-fef7b43bc197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap 95% Confidence Interval for the Mean Height: (14.03, 15.06)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 15\n",
    "sample_std = 2\n",
    "sample_size = 50\n",
    "bootstrap_samples = 10000\n",
    "\n",
    "# Generate original sample data based on given mean and std\n",
    "np.random.seed(42)  # For reproducibility\n",
    "original_sample = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
    "\n",
    "# Function to calculate the mean of a sample\n",
    "def calculate_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "# Generate bootstrap samples and calculate the mean for each\n",
    "bootstrap_means = np.empty(bootstrap_samples)\n",
    "for i in range(bootstrap_samples):\n",
    "    bootstrap_sample = np.random.choice(original_sample, size=sample_size, replace=True)\n",
    "    bootstrap_means[i] = calculate_mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "alpha = 0.05\n",
    "lower_percentile = np.percentile(bootstrap_means, alpha/2*100)\n",
    "upper_percentile = np.percentile(bootstrap_means, (1-alpha/2)*100)\n",
    "\n",
    "print(f\"Bootstrap 95% Confidence Interval for the Mean Height: ({lower_percentile:.2f}, {upper_percentile:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc12cd-a40c-4755-9054-15d3d01f9f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
